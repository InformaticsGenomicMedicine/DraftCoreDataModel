{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package, hgvs, is an easy-to-use Python library for parsing, representing, formatting, and mapping variants between genome, transcript, and protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import hgvs.parser\n",
    "import hgvs.dataproviders.uta\n",
    "# Validating variants: composed of two classes: hgvs.validator.IntrinsicValidator and hgvs.validator.ExtrinsicValidator\n",
    "# Intrinsic validation evaluates a given variant for internal consistency, such as requiring that insertions specify adjacent positions. \n",
    "# Extrinsic validation evaluates a variant using external data, such as ensuring that the reference nucleotide in the variant matches that implied by the reference sequence and position.\n",
    "import hgvs.validator\n",
    "# Normalization is always 3â€™ with respect to the reference sequence. \n",
    "import hgvs.normalizer\n",
    "from hgvs.exceptions import HGVSError\n",
    "\n",
    "\n",
    "hp = hgvs.parser.Parser()\n",
    "hdp = hgvs.dataproviders.uta.connect()\n",
    "hn = hgvs.normalizer.Normalizer(hdp)\n",
    "vr = hgvs.validator.Validator(hdp=hdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hgvs_variants(expression: str) -> str:\n",
    "        \"\"\"Validates the given HGVS expression.\n",
    "\n",
    "        Args:\n",
    "            expression (str): The HGVS expression to validate.\n",
    "\n",
    "        Raises:\n",
    "            HGVSError: If the validation fails.\n",
    "\n",
    "        Returns:\n",
    "            str: The validated HGVS expression.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            parsed_variant = hp.parse_hgvs_variant(expression)\n",
    "            vr.validate(parsed_variant)\n",
    "            return expression\n",
    "        except HGVSError as e:\n",
    "            raise HGVSError(\n",
    "                f\"Validation failed for HGVS expression '{expression}': {e}\"\n",
    "            )\n",
    "        \n",
    "def to_vrs_tranmod(expression):\n",
    "        \"\"\"Convert HGVS, SPDI, gnomad (vcf), beacon to VRS variation. (Using the vrs translate module)\n",
    "\n",
    "        Args:\n",
    "            expression (str): hgvs, spdi, gnomad (vcf) or beacon expression\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the provided input is not a string.\n",
    "\n",
    "        Returns:\n",
    "            dict: VRS object\n",
    "        \"\"\"\n",
    "        hgvs_expression = validate_hgvs_variants(expression)\n",
    "        try: \n",
    "            return tlr.translate_from(str(hgvs_expression),'hgvs')\n",
    "        except Exception as e:\n",
    "            return '{}. Expression Error: {}'.format(e, expression)\n",
    "        \n",
    "\n",
    "for x in [\n",
    "        # Insertion\n",
    "        \"NC_000007.14:g.55181230_55181231insGGCT\", \n",
    "        # Substitution\n",
    "        \"NC_000019.10:g.44908822C>T\",\n",
    "        # Deletion\n",
    "        \"NC_000007.14:g.55181220del\",\n",
    "        # Deletion Insertion\n",
    "        \"NC_000023.11:g.32386323delinsGA\",\n",
    "        # Identity\n",
    "        \"NC_000013.11:g.32936732=\",\n",
    "        # Duplication\n",
    "        \"NC_000013.11:g.19993838_19993839dup\"\n",
    "        ]:\n",
    "     print(to_vrs_tranmod(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ga4gh.vrs.extras.variation_normalizer_rest_dp import VariationNormalizerRESTDataProxy\n",
    "from ga4gh.vrs.dataproxy import SeqRepoRESTDataProxy\n",
    "from ga4gh.vrs.extras.translator import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqrepo_rest_service_url = \"https://services.genomicmedlab.org/seqrepo\"\n",
    "dp = SeqRepoRESTDataProxy(base_url=seqrepo_rest_service_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlr = Translator(data_proxy=dp)\n",
    "hgvs_expr1 = \"NC_000001.11:g.943043C>T\"#\"NM_000097.7:c.814A>C\"\n",
    "allele1 = tlr.translate_from(hgvs_expr1,'hgvs')\n",
    "allele1.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hgvs_variants(expression):\n",
    "    try:\n",
    "        parsed_variant = hp.parse_hgvs_variant(expression)\n",
    "        vr.validate(parsed_variant)\n",
    "        return expression\n",
    "    except HGVSError as e:\n",
    "        return e\n",
    "validate_hgvs_variants('NM_004343.4:c.1154_1155ins5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvs_expr1 = \"NC_000013.11:g.32936732=\"#\"NM_000097.7:c.814A>C\"\n",
    "parsed_variant = hp.parse_hgvs_variant(hgvs_expr1)\n",
    "if not vr.validate(parsed_variant):\n",
    "    raise(ValueError(\"Invalid HGVS expression: %s\" % hgvs_expr1)) \n",
    "# parsed_variant.posedit.edit.ref\n",
    "parsed_variant.posedit.edit.alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = '../data/LabHgvsExpression.xlsx'\n",
    "\n",
    "with pd.ExcelFile(excel_file) as hgvs_path:\n",
    "    input_data = pd.read_excel(hgvs_path)\n",
    "\n",
    "input_data['oringal_hgvs_expression_example'] = input_data['oringal_hgvs_expression_example'].str.strip()\n",
    "input_data['edited_hgvs_expression_expample'] = input_data['edited_hgvs_expression_expample'].str.strip()\n",
    "\n",
    "data = pd.DataFrame(input_data)\n",
    "\n",
    "\n",
    "\n",
    "#NOTE: Boolean Values where obtained from: https://mutalyzer.nl/\n",
    "# Description: The Normalizer takes a variant description as input and checks whether it is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_expression = data['oringal_hgvs_expression_example']\n",
    "edited_expression = data['edited_hgvs_expression_expample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hgvs_variants(hgvs_list):\n",
    "    # boolean_checker = []\n",
    "    error_messages = []\n",
    "\n",
    "    for hgvs in hgvs_list:\n",
    "        try:\n",
    "            parsed_variant = hp.parse_hgvs_variant(hgvs)\n",
    "            vr.validate(parsed_variant)\n",
    "            # boolean_checker.append()\n",
    "            error_messages.append('Passed')\n",
    "        except HGVSError as e:\n",
    "            # boolean_checker.append(False)\n",
    "            error_messages.append(e) \n",
    "    \n",
    "    return boolean_checker, error_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_boolean_checker, original_error_messages = validate_hgvs_variants(original_expression)\n",
    "edited_boolean_checker, edited_error_messages = validate_hgvs_variants(edited_expression)\n",
    "\n",
    "hgvs_results = {\n",
    "    # 'biocommons_hgvs_original_hgvs_checker':original_boolean_checker,\n",
    "    'biocommons_hgvs_original_hgvs_error_messages':original_error_messages,\n",
    "    # 'biocommons_hgvs_edited_hgvs_checker':edited_boolean_checker,\n",
    "    'biocommons_hgvs_edited_hgvs_error_messages':edited_error_messages\n",
    "}\n",
    "\n",
    "biocommons_hgvs_test = pd.DataFrame(hgvs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biocommons_hgvs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([data, biocommons_hgvs_test], axis=1, ignore_index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../data/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import hgvs.parser\n",
    "import hgvs.dataproviders.uta\n",
    "import hgvs.validator\n",
    "from hgvs.exceptions import HGVSError\n",
    "\n",
    "hp = hgvs.parser.Parser()\n",
    "hdp = hgvs.dataproviders.uta.connect()\n",
    "vr = hgvs.validator.Validator(hdp=hdp)\n",
    "\n",
    "# TODO:open different type of files. If the file format doesn't work then throw an error.\n",
    "excel_file = '../data/LabHgvsExpression.xlsx'\n",
    "with pd.ExcelFile(excel_file) as hgvs_path:\n",
    "    input_data = pd.read_excel(hgvs_path)\n",
    "\n",
    "\n",
    "def validate_hgvs_variants(hgvs_list):\n",
    "    error_messages = []\n",
    "\n",
    "    for hgvs in hgvs_list:\n",
    "        try:\n",
    "            parsed_variant = hp.parse_hgvs_variant(hgvs)\n",
    "            vr.validate(parsed_variant)\n",
    "            error_messages.append(True)\n",
    "        except HGVSError as e:\n",
    "            error_messages.append(e) \n",
    "    \n",
    "    return error_messages\n",
    "\n",
    "#TODO:user inputes the column name of there hgvs expression\n",
    "input_data['oringal_hgvs_expression_example'] = input_data['oringal_hgvs_expression_example'].str.strip()\n",
    "\n",
    "data = pd.DataFrame(input_data)\n",
    "hgvs_expression = data['edited_hgvs_expression_expample']\n",
    "\n",
    "original_error_messages = validate_hgvs_variants(hgvs_expression)\n",
    "\n",
    "#TODO: create output file.\n",
    "hgvs_results = {'HGVS':data['oringal_hgvs_expression_example'],\n",
    "                'biocommons_validator':original_error_messages}\n",
    "biocommons_hgvs_test = pd.DataFrame(hgvs_results)\n",
    "biocommons_hgvs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.parse_hgvs_variant('NM_001256850.1:c.1141G>A').posedit.pos.end.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hgvs.validator\n",
    "import hgvs.exceptions\n",
    "vr = hgvs.validator.Validator(hdp=hdp)\n",
    "try:\n",
    "    vr.validate( hp.parse_hgvs_variant('NM_000097.7:c.814A>C') ) \n",
    "    print(\"it worked\")\n",
    "except hgvs.exceptions.HGVSError as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "#NM_000371.4:c.220G>C\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvs_list = ['NC_000017.11:g.43091687delC', 'NC_000007.13.g.21726874G>A']\n",
    "\n",
    "try:\n",
    "    parser = hgvs.parser.Parser()\n",
    "    validator = hgvs.validator.IntrinsicValidator()\n",
    "    \n",
    "    for hgvs in hgvs_list:\n",
    "        variant = parser.parse_hgvs_variant(hgvs)\n",
    "        validator.validate(variant)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "import hgvs.validator\n",
    "import hgvs.exceptions\n",
    "vr = hgvs.validator.Validator(hdp=hdp)\n",
    "try:\n",
    "    vr.validate( hp.parse_hgvs_variant('NM_001267550.2(TTN):c.80006G>A') )\n",
    "except hgvs.exceptions.HGVSError as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "from hgvs.exceptions import HGVSError\n",
    "import hgvs.parser\n",
    "import hgvs.validator\n",
    "\n",
    "hgvs_list = ('NC_000017.11:g.43091687delC', 'NC_000007.13.g.21726874G>A')\n",
    "\n",
    "# Create a validator instance\n",
    "vr = hgvs.validator.Validator(hdp=hdp)\n",
    "\n",
    "# Create a parser instance\n",
    "hp = hgvs.parser.Parser()\n",
    "\n",
    "try:\n",
    "    for hgvs in hgvs_list:\n",
    "        vr.validate(hp.parse_hgvs_variant(hgvs))\n",
    "        print('expression passed: {}'.format(hgvs))\n",
    "except HGVSError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hgvs.parser\n",
    "import hgvs.dataproviders.uta\n",
    "import hgvs.validator\n",
    "from hgvs.exceptions import HGVSError\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "hp = hgvs.parser.Parser()\n",
    "hdp = hgvs.dataproviders.uta.connect()\n",
    "vr = hgvs.validator.Validator(hdp=hdp)\n",
    "\n",
    "excel_file = '/Users/M278428/Documents/rf_lab_projects/DraftCoreDataModel/data/finaltestdata.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['hgvs_expression'] = input_data['hgvs_expression'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvsExamples = input_data['hgvs_expression']\n",
    "hgvsExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hgvs_variants(hgvs_list):\n",
    "    error_messages = []\n",
    "\n",
    "    for hgvs in hgvs_list:\n",
    "        try:\n",
    "            parsed_variant = hp.parse_hgvs_variant(hgvs)\n",
    "            vr.validate(parsed_variant)\n",
    "            error_messages.append(True)\n",
    "        except HGVSError as e:\n",
    "            error_messages.append(e) \n",
    "    \n",
    "    return error_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = validate_hgvs_variants(hgvsExamples)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvs_results = {\n",
    "    'HGVS': hgvsExamples,\n",
    "    'Validator': results\n",
    "}\n",
    "result = pd.DataFrame(hgvs_results) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dev_vrs_installation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
